{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lewybagz/Fooocus/blob/main/UseTHisFooocus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvwe0cMLAzWp",
        "outputId": "e6798c24-9994-4ec4-e8f7-82fc659267f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "--2024-01-01 08:14:34--  https://github.com/camenduru/gperftools/releases/download/v1.0/libtcmalloc_minimal.so.4\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/669786276/620e2e64-be9f-4599-904f-18ee3811e159?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240101%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240101T081434Z&X-Amz-Expires=300&X-Amz-Signature=b308a73f06ee08490a9f4c3957dff805290a7a5cf210268c48289c37dd84f56c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=669786276&response-content-disposition=attachment%3B%20filename%3Dlibtcmalloc_minimal.so.4&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-01-01 08:14:34--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/669786276/620e2e64-be9f-4599-904f-18ee3811e159?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240101%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240101T081434Z&X-Amz-Expires=300&X-Amz-Signature=b308a73f06ee08490a9f4c3957dff805290a7a5cf210268c48289c37dd84f56c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=669786276&response-content-disposition=attachment%3B%20filename%3Dlibtcmalloc_minimal.so.4&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "env: LD_PRELOAD=/content/libtcmalloc_minimal.so.4\n",
            "/content/Fooocus\n",
            "[System ARGV] ['launch.py', '--share']\n",
            "Python 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "Fooocus version: 2.1.859\n",
            "Running on local URL:  http://127.0.0.1:7865\n",
            "Total VRAM 16151 MB, total RAM 52218 MB\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Always offload VRAM\n",
            "Device: cuda:0 Tesla V100-SXM2-16GB : native\n",
            "VAE dtype: torch.float32\n",
            "Using pytorch cross attention\n",
            "Refiner unloaded.\n",
            "Running on public URL: https://396ef3c53efe2afbba.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_g.transformer.text_model.embeddings.position_ids', 'cond_stage_model.clip_l.text_projection'}\n",
            "Base model loaded: /content/drive/MyDrive/Fooocus/Fooocus/models/checkpoints/juggernautXL_version6Rundiffusion.safetensors\n",
            "Request to load LoRAs [['sd_xl_offset_example-lora_1.0.safetensors', 0.1], ['None', 1.0], ['None', 1.0], ['None', 1.0], ['None', 1.0]] for model [/content/drive/MyDrive/Fooocus/Fooocus/models/checkpoints/juggernautXL_version6Rundiffusion.safetensors].\n",
            "Loaded LoRA [/content/drive/MyDrive/Fooocus/Fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors] for UNet [/content/drive/MyDrive/Fooocus/Fooocus/models/checkpoints/juggernautXL_version6Rundiffusion.safetensors] with 788 keys at weight 0.1.\n",
            "Fooocus V2 Expansion: Vocab with 642 words.\n",
            "Fooocus Expansion engine loaded for cuda:0, use_fp16 = True.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.75 seconds\n",
            "App started successful. Use the app with http://127.0.0.1:7865/ or 127.0.0.1:7865 or https://396ef3c53efe2afbba.gradio.live\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the repository path\n",
        "repo = \"/content/Fooocus\"\n",
        "\n",
        "# Set environment variables for optimization\n",
        "os.environ[\"SAFETENSORS_FAST_GPU\"]='1'\n",
        "os.environ[\"CUDA_MODULE_LOADING\"]=\"LAZY\"\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
        "os.environ[\"TCMALLOC_AGGRESSIVE_DECOMMIT\"] = \"t\"\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = \"garbage_collection_threshold:0.9,max_split_size_mb:512\"\n",
        "\n",
        "# Install TCMalloc\n",
        "!wget https://github.com/camenduru/gperftools/releases/download/v1.0/libtcmalloc_minimal.so.4 -O /content/libtcmalloc_minimal.so.4 -c\n",
        "%env LD_PRELOAD=/content/libtcmalloc_minimal.so.4\n",
        "\n",
        "# Clone the repository if it doesn't exist\n",
        "if not os.path.exists(repo):\n",
        "  !git clone https://github.com/lllyasviel/Fooocus\n",
        "  %cd {repo}\n",
        "  !pip install -qqqq -r requirements_versions.txt\n",
        "  !sed -i \"s@sys.argv else None).*@sys.argv else None, share=True)@\" {repo + \"/we\"+\"bui.py\"}\n",
        "\n",
        "# Define paths to the models in Google Drive\n",
        "drive_checkpoint_path = \"/content/drive/MyDrive/Fooocus/Fooocus/models/checkpoints\"\n",
        "drive_loras_path = \"/content/drive/MyDrive/Fooocus/Fooocus/models/loras\"\n",
        "\n",
        "# Ensure the script uses the model paths from Google Drive directly\n",
        "# The script should refer to `drive_checkpoint_path` and `drive_loras_path` for model loading\n",
        "\n",
        "# Change directory to Fooocus\n",
        "%cd /content/Fooocus\n",
        "\n",
        "# Launch the application\n",
        "!python launch.py --share\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!grep -rnw '/content/Fooocus/' -e '/content/drive/MyDrive/fooocus/fooocus/models/'"
      ],
      "metadata": {
        "id": "krkN7UENGAvR"
      },
      "execution_count": 12,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyOhEDk2H4T5PUohYRG+Uvgu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}